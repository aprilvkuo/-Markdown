---
title: 机器学习课---2----示例学习
date: 2017-01-03 11:53:54
tags: [Maching Learning]
categories: [机器学习]
---
# 决策树算法

## ID3算法：
   输入：例子集（正例、反例）；
   输出：决策树
从树的根结点开始，每次都用“最好的属性”划分结点，直到所有结点只含一类例子为止。

## 信息增益 and 信息熵
  gain = 未分裂的信息熵 - [p(权重) * 分裂后每个分支的信息熵]之和.
  信息熵 = -p(正例) log(p(正例)) - p(负例) log(p(负例))

## 归纳偏置
  ID3算法用什么策略从观测到的训练数据泛化以分类未见的实例.
  搜索策略:
  1. 优先选择较短的树而不是较长的.
  2. 选择信息增益高的属性离根节点较近的树.

## 常见问题
  - 不相关属性
  - 不充足属性
  > 叶子节点.两类例子具有相同属性值。没有任何属性可进一步扩展决策树。哪类例子多，叶结点标为哪类。

  - 未知属性值
  >① “最通常值”办法
   ② 决策树方法: 把未知属性作为“类”，原来的类作为“属性”
   ③ Bayesian 方法
   ④ 按比例将未知属性值例子分配到各子集中： 属性A有v个值{A1,…,Av}, A值等于Ai的例子数pi和ni，未知属性值例子数分别为pu和nu, 在生成决策树时Ai的例子数

  - 过拟合
  > 1. 预剪枝
  > 2. 后剪枝
